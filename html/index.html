<html>
<head>
<title>Face Detection Project</title>
<link href='http://fonts.googleapis.com/css?family=Nunito:300|Crimson+Text|Droid+Sans+Mono' rel='stylesheet' type='text/css'>
<link rel="stylesheet" title="Default" href="styles/github.css">
<script src="http://ajax.googleapis.com/ajax/libs/jquery/1.3.2/jquery.min.js"></script>

<link rel="stylesheet" href="highlighting/styles/default.css">
<script src="highlighting/highlight.pack.js"></script>

<style type="text/css">
body {
	margin: 0px;
	width: 100%;
	font-family: 'Crimson Text', serif;
	font-size: 20px;
	background: #fcfcfc;
}
h1 {
	font-family: 'Nunito', sans-serif;
	font-weight: normal;
	font-size: 28px;
	margin: 25px 0px 0px 0px;
	text-transform: lowercase;

}

h2 {
	font-family: 'Nunito', sans-serif;
	font-weight: normal;
	font-size: 32px;
	margin: 15px 0px 35px 0px;
	color: #333;
	word-spacing: 3px;
}

h3 {
	font-family: 'Nunito', sans-serif;
	font-weight: normal;
	font-size: 26px;
	margin: 10px 0px 10px 0px;
	color: #333;
	word-spacing: 2px;
}
h4 {
	font-family: 'Nunito', sans-serif;
	font-weight: normal;
	font-size: 22px;
	margin: 10px 0px 10px 0px;
	color: #333;
	word-spacing: 2px;
}

h5 {
	font-family: 'Nunito', sans-serif;
	font-weight: normal;
	font-size: 18px;
	margin: 10px 0px 10px 0px;
	color: #111;
	word-spacing: 2px;
}

p, li {
	color: #444;
}

a {
	color: #DE3737;
}

.container {
	margin: 0px auto 0px auto;
	width: 1160px;
}

#header {
	background: #333;
	width: 100%;
}

#headersub {
	color: #ccc;
	width: 960px;
	margin: 0px auto 0px auto;
	padding: 20px 0px 20px 0px;
}

.chart {
	width: 480px;
}
.lol {
	font-size: 16px;
	color: #888;
	font-style: italic;
}
.sep {
	height: 1px;
	width: 100%;
	background: #999;
	margin: 20px 0px 20px 0px;
}
.footer{
	font-size: 16px;
}
.latex {
	width: 100%;
}

.latex img {
	display: block;
	margin: 0px auto 0px auto;
}

pre {
	font-family: 'Droid Sans Mono';
	font-size: 14px;
}

table td {
  text-align: center;
  vertical-align: middle;
}

table td img {
  text-align: center;
  vertical-align: middle;
}

#contents a {
}
</style>
<script type="text/javascript">
    hljs.initHighlightingOnLoad();
</script>
</head>
<body>
<div id="header" >
<div id="headersub">
<h1>Aayush Kumar </h1>
</div>
</div>
<div class="container">

<h2> Project 5 / Face Detection with a Sliding Window</h2>

<p>
	In this project, our objective was to train a classifier to detect faces using a sliding window approach and leveraging histograms of orienteed gradients (HOG).
	In order to detect faces at multiple scales of an image, we have adapted our sliding windows to operate on multiple scales of the image.

</p>
<h3>Extra Credit</h3>

<ul>
	<li> Implemented Hard Negative Mining (commented out in final submission for time constraints) </li>
	<li> Augmented positive training data with horizontal reflections of frontal faces </li>
</ul>

<div style="clear:both">
<h3>Getting Positive And Features</h3>

<p>
	For getting positive features, I decided to very simply read in images and accumulate a positive dataset of hog descriptions of each of the pre-cropped images.
	One interesting suggestion that I leveraged was that according to ____, where flipping positive training images of pages leverages the
	symmetric aspect of faces and therefore augment our training data to a certain extent. By doing so, my training accuracy increased from __ to ___.
</p>
<p>
	However, processing the negative images proved to be more interesting, as I sampled descriptions at varying scales of the provided images.
	I used a scaling factor of 0.7 as per the suggestion of Professor Hays. After applying the appropriate labels to my dataset,
	I trained my linear SVM with a lambda of 0.0001. After running my detector several times, I was consistently returning more false positives than I would have liked-
	thus I went ahead and implemented hard negative mining using the provided test data set.
</p>

<h2>Random window approach for Negative Features</h2>

<pre><code>
%My Random Window approach for scanning through neg features
		while (imHeight >= tempSize && imWidth >= tempSize)
            for fS = 1 : ceil(featuresSampled * currScale .^ 2)
                % top left coordinates of feature
                r = ceil(rand * (imHeight - tempSize) + 1);
                c = ceil(rand * (imWidth - tempSize) + 1);
                imWindow = img(r : r + tempSize - 1, c : c + tempSize - 1);
                feature = reshape(vl_hog(imWindow, cellSize), 1, []); %linearize into row vec
                features_neg(featIndex,:) = feature; % append row vec
                featIndex = featIndex + 1;
            end
            img = imresize(img, scaleFactor);
            [imHeight, imWidth] = size(img);
            currScale = currScale * scaleFactor;
        end
</code></pre>
<p>Down the road, I believe it would be worth investigating the benefits of fine tuning the final sampling of negative features such that we get a relatively even amount of samples from each range of magnification.
	For instance, for magnification from 1x to 2x we could take num_sample/2 features, from 2x to 3x we could take num_sample/4, from 3x to 4x we could take num_sample/8, etc... This way
 we avoid the case where we have a disproportionate number of samples from a single scale range. </p>
<h2>Hard Negative Mining</h2>
<p>
	As I attempted to Hard Mine Negatives, I realized that the professor's comment about how hardmining negatives doesn't necessarily help with frontal facial detection and linear classifiers.
	After experimenting with non linear classifiers and realizing how computationally inefficient that route would be, I decided to slightly minimize the effect of these hardmined negatives.
	I did so by only taking into account the negatives that my classifier was quite confident about (more confident than average confidence of false positives).
	Also notably, this was relatively computationally very expensive to run on the large dataset of negative examples as well as to lower my detection threshold to properly leverage the benefits of the technique.
	Nevertheless, this would be something that I would cache in future interations of the detector, as the consistent increase in runtime accuracy is worth the longer initial training duration.
</p>
<pre><code>
	[~, hnConfs, ~, hnFeatures] = run_detector(non_face_scn_path, w, b, feature_params);
	hnFeatures = hnFeatures(find(hnConfs > mean(hnConfs)), :);
	trainingLabels = [trainingLabels; (ones(size(hnFeatures, 1), 1) .* -1)];
	trainingData = [trainingData; hnFeatures];
	[w b] = vl_svmtrain(trainingData', trainingLabels, lamda);
</code></pre>



<h3>Results in a table</h3>
I found that incorporating the mining false positives yielded worse results unless I allowed my program to run past the alotted time limit. Therefore I chose to comment it out, but have still shown the implementation above
With my cell size set to 4, threshold at 1.1, and negative feature selection scaling at 0.6, I was able to achieve an accuracy of 84.2.
2000 gave 0.816 AP. After bumping up the number of negative samples to 25000, I achieved a 0.845 AP.

<center>
	<img src="./classDetects.jpg" width="75%" />

<table border=1>
<tr>
	<td>
		<img src="./AP845.jpg" width="24%" />
		<img src="./GR845.jpg" width="24%" />
		<img src="./HOG845.jpg" width="24%" />
		<img src="./PLOT845.jpg" width="24%" />
	</td>
</tr><tr>
	<td>
		<img src="./AP816.jpg" width="24%" />
		<img src="./GR816.jpg" width="24%" />
		<img src="./HOG816.jpg" width="24%" />
		<img src="./PLOT816.jpg" width="24%" />
	</td>
</tr>

</table>
</center>

<div style="clear:both" >
</div>
</body>
</html>
